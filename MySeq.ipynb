{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMGKfQe6B9uz"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "from colorama import Fore\n",
    "from sklearn.metrics import auc, roc_curve, precision_score, recall_score\n",
    "\n",
    "from utils.vocab import Vocabulary\n",
    "from utils.reader import Data\n",
    "from utils.utils import print_progress, create_checkpoints_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y22zz0vACAyj"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2722,
     "status": "ok",
     "timestamp": 1552477347528,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "EVzGbNJxCQGS",
    "outputId": "ca17a8db-2996-403a-88d2-3474cf75ef1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 11071 samples\n",
      "edadeaedadedededaeda\n",
      "<type 'list'>\n",
      "11071\n",
      "11071\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"batch_size\": 128,\n",
    "    \"embed_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"checkpoints\": \"./checkpoints/\",\n",
    "    \"std_factor\": 6.,\n",
    "    \"dropout\": 0.7,\n",
    "}\n",
    "\n",
    "path_normal_data = \"./datasets/vulnbank_train.txt\"\n",
    "path_anomaly_data = \"./datasets/vulnbank_test.txt\"\n",
    "\n",
    "create_checkpoints_dir(params[\"checkpoints\"])\n",
    "\n",
    "vocab = Vocabulary()\n",
    "params[\"vocab\"] = vocab\n",
    "\n",
    "d = Data(path_normal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnmTWyp9-kmo"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBHwX-jPCcdC"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq():\n",
    "    def __init__(self, args):\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.batch_size = tf.placeholder(tf.int32, [], name='batch_size')\n",
    "        self.max_seq_len = tf.placeholder(tf.int32, [], name='max_seq_len')\n",
    "        self.inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "        self.targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "        self.lengths = tf.placeholder(tf.int32, [None, ], name='lengths')\n",
    "        self.dropout = tf.placeholder(tf.float32, name='dropout')\n",
    "        \n",
    "        self.num_layers = args['num_layers']\n",
    "        self.hidden_size = args['hidden_size']\n",
    "        self.vocab = args['vocab']\n",
    "\n",
    "        dec_input = self._process_decoder_input(\n",
    "            self.targets,\n",
    "            self.vocab.vocab,\n",
    "            tf.to_int32(self.batch_size))\n",
    "\n",
    "        vocab_size = len(self.vocab.vocab)\n",
    "\n",
    "        # Embeddings for inputs\n",
    "        embed_initializer = tf.random_uniform_initializer(-np.sqrt(3), np.sqrt(3))\n",
    "\n",
    "        with tf.variable_scope('embedding'):\n",
    "            embeds = tf.get_variable(\n",
    "                'embed_matrix',\n",
    "                [vocab_size, args['embed_size']],\n",
    "                initializer=embed_initializer,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            enc_embed_input = tf.nn.embedding_lookup(embeds, self.inputs)\n",
    "            \n",
    "        enc_outputs, enc_state = self._encoder(enc_embed_input)\n",
    "        \n",
    "        # Embeddings for outputs\n",
    "        with tf.variable_scope('embedding', reuse=True):\n",
    "            dec_embed_input = tf.nn.embedding_lookup(embeds, dec_input)\n",
    "\n",
    "        dec_outputs = self._decoder(enc_outputs, enc_state, dec_embed_input)\n",
    "\n",
    "        weight, bias = self._weight_and_bias(args['hidden_size'], vocab_size)\n",
    "        outputs = tf.reshape(dec_outputs[0].rnn_output, [-1, args['hidden_size']])\n",
    "        logits = tf.matmul(outputs, weight) + bias\n",
    "\n",
    "        logits = tf.reshape(logits, [-1, self.max_seq_len, vocab_size], name='logits')\n",
    "        self.probs = tf.nn.softmax(logits, name='probs')\n",
    "        self.decoder_outputs = tf.argmax(logits, axis=2)\n",
    "\n",
    "        self.cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits,\n",
    "            labels=self.targets,\n",
    "            name='cross_entropy')\n",
    "        self.batch_loss = tf.identity(tf.reduce_mean(self.cross_entropy, axis=1), name='batch_loss')\n",
    "        self.loss = tf.reduce_mean(self.cross_entropy)\n",
    "\n",
    "        self.train_optimizer = self._optimizer(self.loss)\n",
    "\n",
    "        # Saver\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def _encoder(self, enc_embed_input):\n",
    "        \"\"\"\n",
    "        Adds an encoder to the model architecture.\n",
    "        \"\"\"\n",
    "        cells = [self._lstm_cell(self.hidden_size) for _ in range(self.num_layers)]\n",
    "        multilstm = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        enc_outputs, enc_state = tf.nn.dynamic_rnn(\n",
    "            multilstm,\n",
    "            enc_embed_input,\n",
    "            swap_memory = True,\n",
    "            sequence_length=self.lengths,\n",
    "            dtype=tf.float32)\n",
    "        enc_outputs = tf.concat([enc_outputs[0], enc_outputs[1]], -1)\n",
    "        return enc_outputs,enc_state\n",
    "    \n",
    "    def _decoder(self,enc_outputs, enc_state, dec_embed_input):\n",
    "        \"\"\"\n",
    "        Adds a decoder to the model architecture.\n",
    "        \"\"\"\n",
    "        output_lengths = tf.ones([self.batch_size], tf.int32) * self.max_seq_len\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            dec_embed_input,\n",
    "            output_lengths,\n",
    "            time_major=False)\n",
    "\n",
    "        cells = [self._lstm_cell(self.hidden_size) for _ in range(self.num_layers)]\n",
    "        dec_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "              \n",
    "        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units=self.hidden_size, memory=enc_outputs,memory_sequence_length=self.lengths)\n",
    "        #attention_mechanism = tf.contrib.seq2seq.LuongAttention(num_units=self.rnn_size, memory=encoder_outputs, memory_sequence_length=encoder_inputs_length)\n",
    "\n",
    "        dec_cell = tf.contrib.seq2seq.AttentionWrapper(cell=dec_cell, attention_mechanism=attention_mechanism,attention_layer_size=self.hidden_size, name='Attention_Wrapper')\n",
    "                       \n",
    "\n",
    "        \n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, helper, enc_outputs)\n",
    "        \n",
    "        \n",
    "      \n",
    "        dec_outputs = tf.contrib.seq2seq.dynamic_decode(decoder, impute_finished=True,maximum_iterations=self.max_seq_len)\n",
    "\n",
    "        return dec_outputs\n",
    "    \n",
    "    def _optimizer(self, loss,):\n",
    "        \"\"\"\n",
    "        Optimizes weights given a loss. \n",
    "        \"\"\"\n",
    "        def _learning_rate_decay_fn(learning_rate, global_step):\n",
    "            return tf.train.exponential_decay(learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n",
    "\n",
    "        starting_lr = 0.001\n",
    "        starting_global_step = tf.Variable(0, trainable=False)\n",
    "        optimizer = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=starting_global_step,\n",
    "            learning_rate=starting_lr,\n",
    "            optimizer=tf.train.AdamOptimizer,\n",
    "            learning_rate_decay_fn=lambda lr, gs: _learning_rate_decay_fn(lr, gs),\n",
    "            clip_gradients=5.0)\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "    def _process_decoder_input(self, target_data, char_to_code, batch_size):\n",
    "        \"\"\"\n",
    "        Concatenates the <GO> to the begining of each batch.\n",
    "        \"\"\"\n",
    "        ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "        #print(ending)\n",
    "        dec_input = tf.concat([tf.fill([batch_size, 1], char_to_code['<GO>']), ending], 1)\n",
    "        return dec_input\n",
    "\n",
    "    def _lstm_cell(self, hidden_size):\n",
    "        \"\"\"\n",
    "        Returns LSTM cell with dropout.\n",
    "        \"\"\"\n",
    "        cell = tf.contrib.rnn.LSTMCell(\n",
    "            hidden_size,\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=self.dropout)\n",
    "\n",
    "        return cell\n",
    "\n",
    "    def _weight_and_bias(self, in_size, out_size):\n",
    "        \"\"\"\n",
    "        Initializes weights and biases.\n",
    "        \"\"\"\n",
    "        weight = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.01))\n",
    "        bias = tf.Variable(tf.constant(1., shape=[out_size]))\n",
    "\n",
    "        return weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gp-CqdxM_g1C"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq():\n",
    "    def __init__(self, args):\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.batch_size = tf.placeholder(tf.int32, [], name='batch_size')\n",
    "        self.max_seq_len = tf.placeholder(tf.int32, [], name='max_seq_len')\n",
    "        self.inputs = tf.placeholder(tf.int32, [None, None], name='inputs')\n",
    "        self.targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "        self.lengths = tf.placeholder(tf.int32, [None, ], name='lengths')\n",
    "        self.dropout = tf.placeholder(tf.float32, name='dropout')\n",
    "        \n",
    "        self.num_layers = args['num_layers']\n",
    "        self.hidden_size = args['hidden_size']\n",
    "        self.vocab = args['vocab']\n",
    "\n",
    "        dec_input = self._process_decoder_input(\n",
    "            self.targets,\n",
    "            self.vocab.vocab,\n",
    "            tf.to_int32(self.batch_size))\n",
    "\n",
    "        vocab_size = len(self.vocab.vocab)\n",
    "\n",
    "        # Embeddings for inputs\n",
    "        embed_initializer = tf.random_uniform_initializer(-np.sqrt(3), np.sqrt(3))\n",
    "\n",
    "        with tf.variable_scope('embedding'):\n",
    "            embeds = tf.get_variable(\n",
    "                'embed_matrix',\n",
    "                [vocab_size, args['embed_size']],\n",
    "                initializer=embed_initializer,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            enc_embed_input = tf.nn.embedding_lookup(embeds, self.inputs)\n",
    "            \n",
    "        enc_state = self._encoder(enc_embed_input)\n",
    "        \n",
    "        # Embeddings for outputs\n",
    "        with tf.variable_scope('embedding', reuse=True):\n",
    "            dec_embed_input = tf.nn.embedding_lookup(embeds, dec_input)\n",
    "\n",
    "        dec_outputs = self._decoder(enc_state, dec_embed_input)\n",
    "\n",
    "        weight, bias = self._weight_and_bias(args['hidden_size'], vocab_size)\n",
    "        outputs = tf.reshape(dec_outputs[0].rnn_output, [-1, args['hidden_size']])\n",
    "        logits = tf.matmul(outputs, weight) + bias\n",
    "\n",
    "        logits = tf.reshape(logits, [-1, self.max_seq_len, vocab_size], name='logits')\n",
    "        self.probs = tf.nn.softmax(logits, name='probs')\n",
    "        self.decoder_outputs = tf.argmax(logits, axis=2)\n",
    "\n",
    "        self.cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=logits,\n",
    "            labels=self.targets,\n",
    "            name='cross_entropy')\n",
    "        self.batch_loss = tf.identity(tf.reduce_mean(self.cross_entropy, axis=1), name='batch_loss')\n",
    "        self.loss = tf.reduce_mean(self.cross_entropy)\n",
    "\n",
    "        self.train_optimizer = self._optimizer(self.loss)\n",
    "\n",
    "        # Saver\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def _encoder(self, enc_embed_input):\n",
    "        \"\"\"\n",
    "        Adds an encoder to the model architecture.\n",
    "        \"\"\"\n",
    "        cells = [self._lstm_cell(self.hidden_size) for _ in range(self.num_layers)]\n",
    "        multilstm = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        _, enc_state = tf.nn.dynamic_rnn(\n",
    "            multilstm,\n",
    "            enc_embed_input,\n",
    "            sequence_length=self.lengths,\n",
    "            swap_memory=True,\n",
    "            dtype=tf.float32)\n",
    "        \n",
    "        return enc_state\n",
    "    \n",
    "    def _decoder(self, enc_state, dec_embed_input):\n",
    "        \"\"\"\n",
    "        Adds a decoder to the model architecture.\n",
    "        \"\"\"\n",
    "        output_lengths = tf.ones([self.batch_size], tf.int32) * self.max_seq_len\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            dec_embed_input,\n",
    "            output_lengths,\n",
    "            time_major=False)\n",
    "\n",
    "        cells = [self._lstm_cell(self.hidden_size) for _ in range(self.num_layers)]\n",
    "        dec_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, helper, enc_state)\n",
    "\n",
    "        dec_outputs = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder,\n",
    "            output_time_major=False,\n",
    "            impute_finished=True,\n",
    "            maximum_iterations=self.max_seq_len, swap_memory=True)\n",
    "        \n",
    "        return dec_outputs\n",
    "    \n",
    "    def _optimizer(self, loss,):\n",
    "        \"\"\"\n",
    "        Optimizes weights given a loss. \n",
    "        \"\"\"\n",
    "        def _learning_rate_decay_fn(learning_rate, global_step):\n",
    "            return tf.train.exponential_decay(learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n",
    "\n",
    "        starting_lr = 0.001\n",
    "        starting_global_step = tf.Variable(0, trainable=False)\n",
    "        optimizer = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=starting_global_step,\n",
    "            learning_rate=starting_lr,\n",
    "            optimizer=tf.train.AdamOptimizer,\n",
    "            learning_rate_decay_fn=lambda lr, gs: _learning_rate_decay_fn(lr, gs),\n",
    "            clip_gradients=5.0)\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "    def _process_decoder_input(self, target_data, char_to_code, batch_size):\n",
    "        \"\"\"\n",
    "        Concatenates the <GO> to the begining of each batch.\n",
    "        \"\"\"\n",
    "        ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "        dec_input = tf.concat([tf.fill([batch_size, 1], char_to_code['<GO>']), ending], 1)\n",
    "\n",
    "        return dec_input\n",
    "\n",
    "    def _lstm_cell(self, hidden_size):\n",
    "        \"\"\"\n",
    "        Returns LSTM cell with dropout.\n",
    "        \"\"\"\n",
    "        cell = tf.contrib.rnn.LSTMCell(\n",
    "            hidden_size,\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=self.dropout)\n",
    "\n",
    "        return cell\n",
    "\n",
    "    def _weight_and_bias(self, in_size, out_size):\n",
    "        \"\"\"\n",
    "        Initializes weights and biases.\n",
    "        \"\"\"\n",
    "        weight = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.01))\n",
    "        bias = tf.Variable(tf.constant(1., shape=[out_size]))\n",
    "\n",
    "        return weight, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2024,
     "status": "ok",
     "timestamp": 1552477365894,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "eoixFTvI9qup",
    "outputId": "1ed7c906-5419-4784-b96f-d19e5a6707b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 7, 4, 28, 4, 1], [5, 6, 4, 6, 5, 4, 5, 6, 4, 6, 5, 6, 5, 6, 5, 6, 4, 5, 6, 4, 1], [4, 10, 4, 1], [4, 17, 4, 6, 5, 4, 5, 6, 4, 6, 5, 4, 6, 5, 4, 5, 6, 4, 6, 5, 7, 28, 7, 17, 7, 1], [4, 5, 6, 5, 4, 5, 6, 4, 6, 5, 4, 6, 5, 4, 6, 5, 4, 5, 6, 4, 10, 1], [4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 6, 5, 4, 1], [8, 1], [4, 5, 6, 4, 6, 5, 4, 5, 6, 4, 5, 6, 4, 1], [4, 5, 6, 4, 1], [4, 5, 6, 5, 4, 6, 5, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 7, 18, 1]]\n",
      "[6, 21, 4, 26, 22, 14, 2, 14, 5, 23]\n"
     ]
    }
   ],
   "source": [
    "print(d.data[0:10])\n",
    "print(d.lengths[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTmkM3m8DrRB"
   },
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\n",
    "    def __init__(self, batch_size, checkpoints_path, dropout):\n",
    "        self.batch_size = batch_size\n",
    "        self.checkpoints = checkpoints_path\n",
    "        self.path_to_graph = checkpoints_path + 'seq2seq'\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def train(self, model, train_data, train_size, num_steps, num_epochs, min_loss=0.1):\n",
    "        \"\"\"\n",
    "        Trains a given model architecture with given train data.\n",
    "        \"\"\"\n",
    "        tf.set_random_seed(1234)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            total_loss = []\n",
    "            timings = []\n",
    "            steps_per_epoch = int(train_size / self.batch_size)\n",
    "            num_epoch = 1\n",
    "            \n",
    "            for step in range(1, num_steps):\n",
    "                beg_t = timeit.default_timer()\n",
    "                X, L = train_data.next()\n",
    "                seq_len = np.max(L)\n",
    "\n",
    "                # For anomaly detection problem we reconstruct input data, so\n",
    "                # targets and inputs are identical.\n",
    "                feed_dict = {\n",
    "                    model.inputs: X,\n",
    "                    model.targets: X,\n",
    "                    model.lengths: L,\n",
    "                    model.dropout: self.dropout,\n",
    "                    model.batch_size: self.batch_size,\n",
    "                    model.max_seq_len: seq_len}\n",
    "                \n",
    "                fetches = [model.loss, model.decoder_outputs, model.train_optimizer]\n",
    "                step_loss, _, _ = sess.run(fetches, feed_dict)\n",
    "\n",
    "                total_loss.append(step_loss)\n",
    "                timings.append(timeit.default_timer() - beg_t)\n",
    "\n",
    "                if step % steps_per_epoch == 0:\n",
    "                    num_epoch += 1\n",
    "\n",
    "                if step % 200 == 0 or step == 1:\n",
    "                    print_progress(\n",
    "                        int(step / 200),\n",
    "                        num_epoch,\n",
    "                        np.mean(total_loss),\n",
    "                        np.mean(step_loss),\n",
    "                        np.sum(timings))\n",
    "                    timings = []\n",
    "\n",
    "                if step == 1:\n",
    "                    _ = tf.train.export_meta_graph(filename=self.path_to_graph + '.meta')\n",
    "                \n",
    "                if np.mean(total_loss) < min_loss or num_epoch > num_epochs:\n",
    "                    model.saver.save(sess, self.path_to_graph, global_step=step)\n",
    "                    print(\"Training is finished.\")\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6141,
     "status": "ok",
     "timestamp": 1552477385812,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "5E0ws2IyDvPO",
    "outputId": "29a4c602-1a3c-411f-ab11-c8a15ebf80a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-50565b44c0aa>:19: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-8-50565b44c0aa>:136: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-50565b44c0aa>:68: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-50565b44c0aa>:75: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(params)\n",
    "t = Trainer(params[\"batch_size\"], params[\"checkpoints\"], params[\"dropout\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 924272,
     "status": "ok",
     "timestamp": 1552478310778,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "-Cyqj_RzDw9j",
    "outputId": "c7563f2c-4b9d-4dbd-f19e-2e6f7100a6a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (epoch 1), average_train_loss = 4.27602, step_loss = 4.27602, time_per_step = 1.584\n",
      "Step 1 (epoch 4), average_train_loss = 1.33688, step_loss = 0.56431, time_per_step = 49.109\n",
      "Step 2 (epoch 7), average_train_loss = 0.94964, step_loss = 0.54772, time_per_step = 49.571\n",
      "Step 3 (epoch 10), average_train_loss = 0.77622, step_loss = 0.40292, time_per_step = 49.444\n",
      "Step 4 (epoch 13), average_train_loss = 0.66395, step_loss = 0.27284, time_per_step = 49.241\n",
      "Step 5 (epoch 17), average_train_loss = 0.58083, step_loss = 0.17995, time_per_step = 49.159\n",
      "Step 6 (epoch 20), average_train_loss = 0.51713, step_loss = 0.17119, time_per_step = 49.341\n",
      "Step 7 (epoch 23), average_train_loss = 0.46713, step_loss = 0.20865, time_per_step = 49.380\n",
      "Step 8 (epoch 26), average_train_loss = 0.42638, step_loss = 0.11940, time_per_step = 49.335\n",
      "Step 9 (epoch 30), average_train_loss = 0.39275, step_loss = 0.13402, time_per_step = 49.348\n",
      "Step 10 (epoch 33), average_train_loss = 0.36414, step_loss = 0.08014, time_per_step = 49.373\n",
      "Step 11 (epoch 36), average_train_loss = 0.33991, step_loss = 0.10242, time_per_step = 49.225\n",
      "Step 12 (epoch 39), average_train_loss = 0.31907, step_loss = 0.09913, time_per_step = 49.086\n",
      "Step 13 (epoch 42), average_train_loss = 0.30076, step_loss = 0.07541, time_per_step = 48.969\n",
      "Step 14 (epoch 46), average_train_loss = 0.28473, step_loss = 0.06191, time_per_step = 49.317\n",
      "Step 15 (epoch 49), average_train_loss = 0.27047, step_loss = 0.05838, time_per_step = 49.165\n",
      "Step 16 (epoch 52), average_train_loss = 0.25794, step_loss = 0.10482, time_per_step = 49.615\n",
      "Step 17 (epoch 55), average_train_loss = 0.24666, step_loss = 0.04643, time_per_step = 49.080\n",
      "Step 18 (epoch 59), average_train_loss = 0.23627, step_loss = 0.05657, time_per_step = 49.150\n",
      "Training is finished.\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10 ** 6\n",
    "num_epochs = 60\n",
    "\n",
    "train_gen = d.train_generator(params[\"batch_size\"], num_epochs)\n",
    "train_size = d.train_size\n",
    "\n",
    "t.train(model, train_gen, train_size, num_steps, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsGZXxpdHH8F"
   },
   "outputs": [],
   "source": [
    "class Predictor():\n",
    "    def __init__(self, checkpoints_path, std_factor, vocab):\n",
    "\n",
    "        self.threshold = 0.\n",
    "        self.checkpoints = checkpoints_path\n",
    "        self.path_to_graph = checkpoints_path + 'seq2seq'\n",
    "        self.std_factor = std_factor\n",
    "        self.vocab = vocab\n",
    "        self.__load()\n",
    "\n",
    "    def __load(self):\n",
    "        \"\"\"\n",
    "        Loads model from the checkpoint directory and sets models params. \n",
    "        \"\"\"\n",
    "        try:\n",
    "            loaded_graph = tf.Graph()\n",
    "            with loaded_graph.as_default():\n",
    "                saver = tf.train.import_meta_graph(\n",
    "                    self.path_to_graph + '.meta')\n",
    "\n",
    "            self.sess = tf.Session(graph=loaded_graph)\n",
    "            saver.restore(self.sess, tf.train.latest_checkpoint(\n",
    "                self.checkpoints))\n",
    "\n",
    "            # loading model parameters\n",
    "            self.inputs = loaded_graph.get_tensor_by_name('inputs:0')\n",
    "            self.targets = loaded_graph.get_tensor_by_name('targets:0')\n",
    "            self.lengths = loaded_graph.get_tensor_by_name('lengths:0')\n",
    "            self.dropout = loaded_graph.get_tensor_by_name('dropout:0')\n",
    "            self.batch_size_tensor = loaded_graph.get_tensor_by_name('batch_size:0')\n",
    "            self.seq_len_tensor = loaded_graph.get_tensor_by_name('max_seq_len:0')\n",
    "            self.get_batch_loss = loaded_graph.get_tensor_by_name('batch_loss:0')\n",
    "            self.get_probabilities = loaded_graph.get_tensor_by_name('probs:0')\n",
    "            self.get_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError('Unable to create model: {}'.format(e))\n",
    "\n",
    "    def set_threshold(self, data_gen):\n",
    "        \"\"\"\n",
    "        Calculates threshold for anomaly detection.\n",
    "        \"\"\"\n",
    "        \n",
    "        total_loss = []\n",
    "        for seq, l in data_gen:\n",
    "            batch_loss, _ = self._predict_for_request(seq, l)\n",
    "            total_loss.extend(batch_loss)\n",
    "\n",
    "        mean = np.mean(total_loss)\n",
    "        std = np.std(total_loss)\n",
    "        self.threshold = mean + self.std_factor * std\n",
    "\n",
    "        print('Validation loss mean: ', mean)\n",
    "        print('Validation loss std: ', std)\n",
    "        print('Threshold for anomaly detection: ', self.threshold)\n",
    "        \n",
    "        return self.threshold\n",
    "\n",
    "    def predict(self, data_gen, visual=True):\n",
    "        \"\"\"\n",
    "        Predicts probabilities and loss for given sequences.\n",
    "        \"\"\"\n",
    "        loss = []\n",
    "        predictions = []\n",
    "        num_displayed = 0\n",
    "        \n",
    "        for seq, l in data_gen:\n",
    "            batch_loss, alphas = self._predict_for_request(seq, l)\n",
    "            #print('Batchloss:',batch_loss)\n",
    "            #print('alphas:',alphas)\n",
    "            #print('shape,alphas:',alphas.shape)\n",
    "            loss.extend(batch_loss)\n",
    "            alphas = self._process_alphas(seq, alphas, 1)\n",
    "            mask = np.array([l > self.threshold for l in batch_loss])\n",
    "            final_pred = mask.astype(int)\n",
    "            predictions.extend(final_pred)\n",
    "            \n",
    "            if visual and num_displayed < 10 and final_pred == [1]:\n",
    "              \n",
    "                print('\\n\\nPrediction: ', final_pred[0])\n",
    "                print('Loss ', batch_loss[0])\n",
    "                \n",
    "                num_displayed += 1 \n",
    "                self._visual(alphas, seq)\n",
    "        \n",
    "        return predictions, loss\n",
    "\n",
    "    def _predict_for_request(self, X, l):\n",
    "        \"\"\"\n",
    "        Predicts probabilities and loss for given data. \n",
    "        \"\"\"\n",
    "        lengths = [l]\n",
    "        max_seq_len = l\n",
    "        feed_dict = {\n",
    "            self.inputs: X,\n",
    "            self.targets: X,\n",
    "            self.lengths: lengths,\n",
    "            self.dropout: 1.0,\n",
    "            self.batch_size_tensor: 1,\n",
    "            self.seq_len_tensor: max_seq_len}\n",
    "\n",
    "        fetches = [self.get_batch_loss, self.get_probabilities]\n",
    "        #print('fetches:',self.sess.run(fetches))\n",
    "        batch_loss, alphas = self.sess.run(fetches, feed_dict=feed_dict)\n",
    "        #这里的 alpha是预测出来的行为序列的向量形式size为[1*len_sentence*72]\n",
    "        return batch_loss, alphas\n",
    "\n",
    "    def _process_alphas(self, X, alphas, batch_size):\n",
    "        \"\"\"\n",
    "        Counts numbers as probabilities for given data sample.\n",
    "        \"\"\"\n",
    "        processed_alphas = []\n",
    "        for i in range(batch_size):\n",
    "           \n",
    "            probs = alphas[i]\n",
    "            coefs = np.array([probs[j][X[i][j]] for j in range(len(X[i]))])\n",
    "            coefs = coefs / coefs.max()\n",
    "            processed_alphas.append(coefs)\n",
    "            \n",
    "        return processed_alphas\n",
    "\n",
    "    def _visual(self, alphas, X):\n",
    "        \"\"\"\n",
    "        Colors sequence of malicious characters.\n",
    "        \"\"\"\n",
    "        for i, x in enumerate(X):\n",
    "            coefs = alphas[i]\n",
    "            tokens = self.vocab.int_to_string(x)\n",
    "            \n",
    "            for j in range(len(x)):\n",
    "                token = tokens[j]\n",
    "                if coefs[j] < 0.09:\n",
    "                    c = Fore.RED\n",
    "                else:\n",
    "                    c = Fore.BLACK\n",
    "                if token != '<PAD>' and token != '<EOS>':\n",
    "                    token = ''.join(c + token)\n",
    "                    print(token, end='')\n",
    "                    \n",
    "            print(Fore.BLACK + '', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2453,
     "status": "ok",
     "timestamp": 1552478811719,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "3h1U_bUsHjuk",
    "outputId": "48c6574b-ca4f-4362-b6aa-fa8762426e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/seq2seq-3720\n"
     ]
    }
   ],
   "source": [
    "p = Predictor(params[\"checkpoints\"], params[\"std_factor\"], params[\"vocab\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74876,
     "status": "ok",
     "timestamp": 1552478886186,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "a8_yam2LHoSW",
    "outputId": "df4bd686-89fd-4485-8bd0-0d7a732201bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss mean:  0.134033\n",
      "Validation loss std:  0.3600101\n",
      "Threshold for anomaly detection:  2.294093519449234\n"
     ]
    }
   ],
   "source": [
    "val_gen = d.val_generator()\n",
    "threshold = p.set_threshold(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42406,
     "status": "ok",
     "timestamp": 1552478932605,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "yE915E8jHsul",
    "outputId": "a59aa7b6-9850-4ff1-d3b1-c0bcedf52da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.511054\n",
      "\u001b[31m4\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  3.1032686\n",
      "\u001b[31mR\u001b[30mF\u001b[31m%\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.6767395\n",
      "\u001b[30ma\u001b[30me\u001b[30ma\u001b[30me\u001b[30ma\u001b[30me\u001b[30ma\u001b[30me\u001b[30ma\u001b[30me\u001b[30ma\u001b[30me\u001b[30ma\u001b[30me\u001b[30ma\u001b[30me\u001b[30ma\u001b[30me\u001b[30ma\u001b[31me\u001b[31mq\u001b[31mT\u001b[31mG\u001b[31mT\u001b[31mG\u001b[31mT\u001b[31mG\u001b[31mT\u001b[31mG\u001b[31mw\u001b[31mb\u001b[31mp\u001b[30mb\u001b[31mp\u001b[30mb\u001b[31mp\u001b[30mb\u001b[30mw\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.7230406\n",
      "\u001b[30mg\u001b[30mb\u001b[30mg\u001b[30mb\u001b[30mg\u001b[30mb\u001b[30mg\u001b[31mb\u001b[30mg\u001b[31mb\u001b[30mg\u001b[31mr\u001b[30mg\u001b[31mb\u001b[30mg\u001b[31mr\u001b[30mg\u001b[31mr\u001b[30mg\u001b[31mr\u001b[31mg\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.637253\n",
      "\u001b[31mC\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  3.843855\n",
      "\u001b[30ma\u001b[30mb\u001b[30ma\u001b[30mb\u001b[31mC\u001b[30ma\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31ma\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[30mb\u001b[31mC\u001b[31mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[30m"
     ]
    }
   ],
   "source": [
    "test_gen = d.test_generator()\n",
    "valid_preds, valid_loss = p.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1806,
     "status": "ok",
     "timestamp": 1552478943445,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "dFv8vIE4JdFk",
    "outputId": "6401b1b6-f133-4517-f5b4-ceb75ebaa8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of FP:  6\n",
      "Number of samples:  1108\n",
      "FP rate: 0.0054\n"
     ]
    }
   ],
   "source": [
    "print('Number of FP: ', np.sum(valid_preds))\n",
    "print('Number of samples: ', len(valid_preds))\n",
    "print('FP rate: {:.4f}'.format(np.sum(valid_preds) / len(valid_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 522239,
     "status": "ok",
     "timestamp": 1552479471281,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "VdBKQ73OJjCr",
    "outputId": "cee7c6d8-ac6a-4da7-c690-417ab1a57ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 14242 samples\n",
      "a\n",
      "<type 'list'>\n",
      "14242\n",
      "14242\n",
      "\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.679546\n",
      "\u001b[30mb\u001b[31mp\u001b[30mb\u001b[30mp\u001b[30mb\u001b[30mp\u001b[30mb\u001b[30mp\u001b[30mb\u001b[30mn\u001b[30mb\u001b[30mn\u001b[30mb\u001b[30mp\u001b[30mb\u001b[30mn\u001b[30mb\u001b[31mI\u001b[30mb\u001b[31mI\u001b[30mb\u001b[30mo\u001b[30mb\u001b[31mI\u001b[30mb\u001b[30mn\u001b[30mb\u001b[30mo\u001b[30mb\u001b[30mo\u001b[30mb\u001b[30mo\u001b[30mb\u001b[31mI\u001b[30mb\u001b[31mI\u001b[30mb\u001b[30mo\u001b[30mb\u001b[31mI\u001b[30mb\u001b[30mn\u001b[30mb\u001b[30mo\u001b[30mb\u001b[31mI\u001b[30mb\u001b[31mI\u001b[30mb\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[30mo\u001b[31mI\u001b[31mo\u001b[31mI\u001b[31mo\u001b[31mI\u001b[31mo\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.3347137\n",
      "\u001b[31mV\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  3.006544\n",
      "\u001b[31mk\u001b[30md\u001b[30me\u001b[30ma\u001b[31mk\u001b[30me\u001b[30md\u001b[30ma\u001b[31mv\u001b[31mk\u001b[31mv\u001b[30mk\u001b[31me\u001b[31md\u001b[30ma\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.511054\n",
      "\u001b[31m4\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  5.1383805\n",
      "\u001b[31ma\u001b[31mb\u001b[31ma\u001b[31mb\u001b[31mC\u001b[30ma\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31ma\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mb\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[30mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[31mo\u001b[31mC\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.356697\n",
      "\u001b[31m<UNK>\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  5.758702\n",
      "\u001b[30ma\u001b[31md\u001b[30ma\u001b[31md\u001b[30me\u001b[30ma\u001b[30mm\u001b[30ma\u001b[30mm\u001b[30ma\u001b[30me\u001b[31md\u001b[30ma\u001b[30mm\u001b[31ma\u001b[30mm\u001b[31ma\u001b[30mm\u001b[31ma\u001b[31mA\u001b[31mH\u001b[31mA\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mw\u001b[31mM\u001b[31mz\u001b[30mw\u001b[31mz\u001b[31mM\u001b[30mw\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mM\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mR\u001b[31mF\u001b[31mR\u001b[31mF\u001b[30mz\u001b[31mR\u001b[31mF\u001b[31mR\u001b[31mF\u001b[31mR\u001b[31mF\u001b[31mR\u001b[31mF\u001b[31mR\u001b[31mF\u001b[31mR\u001b[31mF\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[30mw\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mF\u001b[30mz\u001b[31mF\u001b[30mz\u001b[31mD\u001b[31m$\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mw\u001b[30mz\u001b[30mw\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mD\u001b[31mK\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mR\u001b[31mF\u001b[30mz\u001b[31mF\u001b[30mz\u001b[31mR\u001b[31mF\u001b[30mz\u001b[31mF\u001b[30mz\u001b[31mF\u001b[30mz\u001b[31m$\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[31mD\u001b[30mK\u001b[31mB\u001b[31mR\u001b[31mF\u001b[30mz\u001b[31mF\u001b[30mz\u001b[31mF\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mB\u001b[30mz\u001b[31mR\u001b[31mF\u001b[30mz\u001b[31mD\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mF\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mB\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mw\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[31mM\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mK\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mw\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mM\u001b[31mK\u001b[30mz\u001b[31mH\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mY\u001b[31mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mH\u001b[31mM\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mM\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mH\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mY\u001b[31mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mw\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mY\u001b[31mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mD\u001b[31mM\u001b[30mz\u001b[31m8\u001b[30mz\u001b[31mH\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mY\u001b[31mK\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mw\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mw\u001b[31mH\u001b[31mD\u001b[30mz\u001b[31mB\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31m8\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mw\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mY\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mY\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mB\u001b[30mz\u001b[31mB\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mH\u001b[30mz\u001b[30mK\u001b[30mz\u001b[30mK\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mH\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[30mw\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31m8\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mA\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[31mM\u001b[30mz\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mD\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mM\u001b[31mH\u001b[31mz\u001b[31mW\u001b[31mD\u001b[31mW\u001b[31mD\u001b[31mW\u001b[31mD\u001b[31mW\u001b[31mD\u001b[31mW\u001b[31mD\u001b[31mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mH\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mw\u001b[30mz\u001b[31mw\u001b[30mz\u001b[31mH\u001b[31mw\u001b[31mz\u001b[31mw\u001b[31mz\u001b[31mH\u001b[31mD\u001b[31mw\u001b[31mz\u001b[31mH\u001b[31mD\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[30mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[31mM\u001b[30mz\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mM\u001b[30mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[30mz\u001b[31mw\u001b[30mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mY\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mY\u001b[30mz\u001b[31mK\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mK\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[31mK\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mw\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31m8\u001b[31mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31m3\u001b[31mM\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[31mW\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mM\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mW\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mw\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mM\u001b[31mD\u001b[30mz\u001b[31mM\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mH\u001b[30mz\u001b[31mD\u001b[30mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mM\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mw\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mw\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mH\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mW\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mK\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mK\u001b[31mz\u001b[31mK\u001b[31mM\u001b[31mz\u001b[31mK\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mY\u001b[31mz\u001b[31mK\u001b[31mz\u001b[31mK\u001b[31mz\u001b[31mY\u001b[31mz\u001b[31mK\u001b[31mY\u001b[31mK\u001b[31mz\u001b[31mK\u001b[31mH\u001b[31mK\u001b[31mz\u001b[31mK\u001b[31mz\u001b[31mK\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mK\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mw\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mw\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mH\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mD\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mM\u001b[31mz\u001b[31mD\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.5311792\n",
      "\u001b[31m7\u001b[31mb\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.343672\n",
      "\u001b[31m7\u001b[30m\n",
      "\n",
      "Prediction:  1\n",
      "Loss  2.4418588\n",
      "\u001b[31mA\u001b[30m"
     ]
    }
   ],
   "source": [
    "pred_data = Data(path_anomaly_data, predict=True)\n",
    "pred_gen = pred_data.predict_generator()\n",
    "anomaly_preds, anomaly_loss = p.predict(pred_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2795,
     "status": "ok",
     "timestamp": 1552479629939,
     "user": {
      "displayName": "wen sen",
      "photoUrl": "",
      "userId": "00289715096948395151"
     },
     "user_tz": -480
    },
    "id": "eZH1NkBQ8_lx",
    "outputId": "1ec987df-f392-408e-a32b-9de7ef925570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TP:  14189\n",
      "Number of samples:  14242\n",
      "TP rate: 0.9963\n"
     ]
    }
   ],
   "source": [
    "print('Number of TP: ', len(anomaly_preds)-np.sum(anomaly_preds))\n",
    "print('Number of samples: ', len(anomaly_preds))\n",
    "print('TP rate: {:.4f}'.format((len(anomaly_preds)-np.sum(anomaly_preds)) / len(anomaly_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dy1XfLspBxai"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MySeq.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
